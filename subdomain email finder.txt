import requests
from bs4 import BeautifulSoup
import re

# Function to fetch subdomains from a website
def fetch_subdomains(url):
    subdomains = []
    try:
        response = requests.get(url)
        soup = BeautifulSoup(response.text, 'html.parser')
        links = soup.find_all('a', href=True)
        for link in links:
            href = link['href']
            if href.startswith('http://') or href.startswith('https://'):
                subdomain = re.findall(r'http[s]?://([^.]+)\.', href)
                if subdomain:
                    subdomains.append(subdomain[0])
    except Exception as e:
        print('Error:', str(e))
    return subdomains

# Function to fetch email addresses from a website
def fetch_email_addresses(url):
    email_addresses = []
    try:
        response = requests.get(url)
        soup = BeautifulSoup(response.text, 'html.parser')
        email_regex = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        email_addresses = re.findall(email_regex, soup.get_text())
    except Exception as e:
        print('Error:', str(e))
    return email_addresses

# Main function
def main():
    url = input('Enter the website URL: ')
    subdomains = fetch_subdomains(url)
    email_addresses = fetch_email_addresses(url)

    print('[+] Subdomains:')
    for subdomain in subdomains:
        print(subdomain)

    print('\n[+] Email Addresses:')
    for email_address in email_addresses:
        print(email_address)

if _name_ == '_main_':
    main()